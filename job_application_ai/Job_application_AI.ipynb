{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f8e33c-e9fa-412a-ac5a-2c5a40feab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2498fe-22af-4db5-9e5a-5759944d6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from crewai lib\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47f7ede-e49c-4a3a-9e22-4be086e7c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_openai_api_key\n",
    "\n",
    "openai_api_key = get_openai_api_key()\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2975c825-42bb-46f1-94d3-82e2d8702715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', '', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\USER']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a7f04b-18ba-402a-8b21-67a3c0d09d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/USER/MyProjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43557be0-a3d2-4b50-8ce1-bf25c275d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists('C:/Users/USER/MyProjects/myCV.docx'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56262237-8200-47a8-9d3f-5744ea87ce7d",
   "metadata": {},
   "source": [
    "crewai tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec80b07-1d9b-4382-bf43-909d386fb1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m scrape_tool \u001b[38;5;241m=\u001b[39m ScrapeWebsiteTool()\n\u001b[0;32m     10\u001b[0m read_resume \u001b[38;5;241m=\u001b[39m FileReadTool(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./myCV.docx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m semantic_search_resume \u001b[38;5;241m=\u001b[39m MDXSearchTool(mdx\u001b[38;5;241m=\u001b[39m\u001b[43mfull_text\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_text' is not defined"
     ]
    }
   ],
   "source": [
    "from crewai_tools import (\n",
    "  FileReadTool,\n",
    "  ScrapeWebsiteTool,\n",
    "  MDXSearchTool,\n",
    "  SerperDevTool\n",
    ")\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "read_resume = FileReadTool(file_path='./myCV.docx')\n",
    "semantic_search_resume = MDXSearchTool(mdx=full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8c734-8615-4701-b0f7-e87add4aa113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221a6931-b5ae-4467-ada6-0895a11190f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGWE OGECHI FAITH\n",
      "K. Uzor Avenue, Imo state, Nigeria | 08069447158| ogechifaith78@gmail.com| www.linkedin/in/ogechifaith| https://github.com/Ogechifaith-analytics\n",
      "\n",
      "SUMMARY\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Proactive Program officer with CCBA and CAPM certifications, proficient in Agile methodologies, Microsoft Office, SQL and dashboard creation. With 3+ years of experience managing projects in the nonprofit industry, I excel in leadership, problem-solving, analytical thinking, and effective communication.\n",
      "\n",
      "As a dedicated aspiring data scientist, my goal is to leverage data-driven solutions to address critical challenges in agriculture and food security, starting from my community. With the support of the Mastercard Foundation Scholarship, I aim to enhance my technical skills, expand my knowledge and build networks, enabling me to implement innovative agricultural practices that foster sustainable development. \n",
      "My passion for data science stems from a deep desire to leverage technology in creating lasting positive impact through informed decision-making and effective resource management.\n",
      "\n",
      "WORK EXPERIENCE\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Team Project Manager   \t\t\t\t\t\t\t   July - August 2024\n",
      "ALX Professional Foundation Project\n",
      "\n",
      "Applied analytical thinking and problem-solving skills to conduct research and data analysis, identifying the key challenges contributing to post-harvest losses of farm products.\n",
      "\n",
      "Led a cross-functional team in designing a software solution that will create a platform for farmers to connect with buyers and better logistics aimed at reducing post-harvest losses and increasing revenue by 18%.\n",
      "\n",
      "Designed questionnaire, user stories, and sprint planning document used for requirement gathering and development of actionable tasks.\n",
      "\n",
      "Program Officer (Project Analyst) \t\t\t\t          January 2021 - December 2023\n",
      "Golden Heart Foundation - Nigeria\n",
      "\n",
      "Drove successful project implementation by gathering requirements, managing project workflows, and developing strategies that aligned with the organization’s objectives.\n",
      "\n",
      "Collaborated closely with cross-functional teams and stakeholders, utilizing MS Excel for data visualization and reporting, optimizing program design and resource allocation, resulting in a 25% cost reduction.\n",
      "\n",
      "Maintained comprehensive project documentation, including project plans, performance metrics, and status reports, ensuring alignment with the organization’s goals.\n",
      "\n",
      "Administrative Assistant\t\t\t\t\t          January 2019 - December 2020  \n",
      "Golden Heart Foundation - Nigeria\n",
      "\n",
      "Built and maintained a comprehensive membership database by actively updating and managing members’ data in HubSpot CRM. Communicated effectively with members across email, social media, and phone, showcasing excellent organizational and communication skills.\n",
      "\n",
      "Improved members’ and staff satisfaction rate by 15% through consistently maintaining a polite, empathetic attitude, and implementing feedbacks, highlighting my strengths in customer service, active listening, and conflict resolution.\n",
      "\n",
      "Increased the organization’s membership retention by 11% by enhancing inter-departmental co-operation and recommended improved service offerings, demonstrating strong problem-solving and sales skills.\n",
      "\n",
      "Farm Operations Coordinator\t\t\t\t\t      November 2017 - November 2018  \n",
      "Page One Farms Ltd - Nigeria\n",
      "\n",
      "Coordinated farm activities, ensured timely execution of processes, developed operational strategies to optimize labor and resource management. By implementing an efficient payment system for laborers, I improved payment processing time by 15%, which led to better labor relations and retention.\n",
      "\n",
      "Served as a key liaison between the farm and buyers, ensuring prompt communication once produce became available. This approach contributed to a 20% reduction in post-harvest losses, thereby enhancing sales efficiency and profit.\n",
      "\n",
      "Prepared monthly reports using Excel. This allowed the management team to make data-driven decisions that improved overall productivity by ensuring timely adjustments to operational plans.\n",
      "\n",
      "PROJECTS\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Data Cleaning Project\n",
      "Carried out data cleaning, manipulation and standardization, highlighting my ability to structure and process data, making it ready for analysis in real-world scenarios.\n",
      " Tool used: MySQL (https://github.com/Ogechifaith-analytics/data-cleaning-project)\n",
      "\n",
      "Sales analysis of transportation modes across 21 countries\n",
      "Utilized SQL, Excel and PowerBi to analyze and visualize sales performance across various modes of transportation in 21 different countries. (https://github.com/Ogechifaith-analytics/project)\n",
      "\n",
      "VOLUNTEER\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Programs Coordinator, HYPE Foundation\t\t\t         January 2019 - August 2023\n",
      "\n",
      "HYPE (Harnessing Young Potentials Early) Foundation is an NGO with the goal of helping teens discover and harness their potentials. As Programs Coordinator in Aba, Abia State, I effectively collaborated with stakeholders and team members to design programs that addressed the challenges of targeted audiences, thereby optimizing resource allocation and achieving the organization’s goals.\n",
      "\n",
      "SKILLS\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Technical skills: SQL, PowerBi, Asana, Microsoft Office & Google Workspace\n",
      "Soft skills: Project management, Analytical thinking, Problem solving, Effective communication, Leadership, Data analysis\n",
      "\n",
      "INTERESTS\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Job creation, Data Science and analytics, Information technology, Personal Development Coach\n",
      "\n",
      "EDUCATION\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "BACHELOR OF AGRICULTURE \t\t\t\tOctober 2012 - February 2017\n",
      "University of Port Harcourt, Nigeria \n",
      "Major: Agric Economics, 2nd Class Upper\n",
      "\n",
      "Certifications\n",
      "Data Analytics - ALX Africa (In progress, to be completed in November, 2024)\n",
      "Introduction to SQL - Simplilearn, May 2024\n",
      "CAPM Certification - Simplilearn, April 2023\n",
      "Certification of Capacity in Business Analysis (CCBA) - Simplilearn, January 2023\n",
      "Building rapport with customers – LinkedIn Learning, August 2023\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Load the .docx file\n",
    "doc = Document('C:/Users/USER/MyProjects/myCV.docx')\n",
    "\n",
    "# Extract the text content\n",
    "text = []\n",
    "for paragraph in doc.paragraphs:\n",
    "    text.append(paragraph.text)\n",
    "\n",
    "# Combine the paragraphs into one string\n",
    "full_text = '\\n'.join(text)\n",
    "print(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35163d0e-ff58-4857-9d61-5823844abce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Load the .docx file\n",
    "doc = Document('C:/Users/USER/MyProjects/myCV.docx')\n",
    "\n",
    "# Extract the text content\n",
    "text = []\n",
    "for paragraph in doc.paragraphs:\n",
    "    text.append(paragraph.text)\n",
    "\n",
    "# Combine the paragraphs into one string\n",
    "full_text = '\\n'.join(text)\n",
    "print(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a34509-eefa-41a8-a4de-0e4dce35228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_resume.md', 'w', encoding='utf-8') as temp_file:\n",
    "    temp_file.write(full_text)\n",
    "\n",
    "semantic_search_resume = MDXSearchTool(mdx='temp_resume.md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdae241-1bc1-47a8-a86f-7f8c2b8b8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import (\n",
    "  FileReadTool,\n",
    "  ScrapeWebsiteTool,\n",
    "  MDXSearchTool,\n",
    "  SerperDevTool\n",
    ")\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "read_resume = FileReadTool(file_path='./temp_resume.md')\n",
    "semantic_search_resume = MDXSearchTool(mdx='temp_resume.md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf7006-7f8d-47f2-9b1a-4eabe518c706",
   "metadata": {},
   "outputs": [],
   "source": [
    " from IPython.display import Markdown, display\n",
    "display(Markdown(\"./temp_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb06a6-5206-45e2-a356-85d081798a1e",
   "metadata": {},
   "source": [
    "**creating agents**\n",
    "-Define your Agents, and provide them a role, goal and backstory.\n",
    "-It has been seen that LLMs perform better when they are role playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813683a-c534-42d4-966f-f8e1cfb7de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Researcher\n",
    "researcher = Agent(\n",
    "    role=\"Tech Job Researcher\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "         \"job posting to help job applicants\",\n",
    "    tools = [scrape_tool, search_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"navigating and extracting critical \"\n",
    "        \"information from job postings is unmatched.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a6e21-33a9-44cf-b8ee-5262d2af1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Profiler\n",
    "profiler = Agent(\n",
    "    role=\"Personal Profiler for Data Analyst\",\n",
    "    goal=\"Do increditble research on job applicants \"\n",
    "         \"to help them stand out in the job market\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Equipped with analytical prowess, you dissect \"\n",
    "        \"and synthesize information \"\n",
    "        \"from diverse sources to craft comprehensive \"\n",
    "        \"personal and professional profiles, laying the \"\n",
    "        \"groundwork for personalized resume enhancements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039596a-4d82-4616-b798-bd55487ec56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Resume Strategist\n",
    "resume_strategist = Agent(\n",
    "    role=\"Resume Strategist for Data Analyst\",\n",
    "    goal=\"Find all the best ways to make a \"\n",
    "         \"resume stand out in the job market.\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"With a strategic mind and an eye for detail, you \"\n",
    "        \"excel at refining resumes to highlight the most \"\n",
    "        \"relevant skills and experiences, ensuring they \"\n",
    "        \"resonate perfectly with the job's requirements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccb63a-d2ff-40ab-912c-ca0109f9c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 4: Interview Preparer\n",
    "interview_preparer = Agent(\n",
    "    role=\"Data Analyst Interview Preparer\",\n",
    "    goal=\"Create interview questions and talking points \"\n",
    "         \"based on the resume and job requirements\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Your role is crucial in anticipating the dynamics of \"\n",
    "        \"interviews. With your ability to formulate key questions \"\n",
    "        \"and talking points, you prepare candidates for success, \"\n",
    "        \"ensuring they can confidently address all aspects of the \"\n",
    "        \"job they are applying for.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099d83a-2a95-4592-bcc9-0be01eb80d5e",
   "metadata": {},
   "source": [
    "Creating Tasks\n",
    "Define your Tasks, and provide them a description, expected_output and agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f203b-ab85-4c0d-8889-e331eefb0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Researcher Agent: Extract Job Requirements\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
    "        \"to extract key skills, experiences, and qualifications \"\n",
    "        \"required. Use the tools to gather content and identify \"\n",
    "        \"and categorize the requirements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary \"\n",
    "        \"skills, qualifications, and experiences.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e9357-7514-45ed-ac41-aeea678c7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Profiler Agent: Compile Comprehensive Profile\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Compile a detailed personal and professional profile \"\n",
    "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
    "        \"({personal_writeup}). Utilize tools to extract and \"\n",
    "        \"synthesize information from these sources.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive profile document that includes skills, \"\n",
    "        \"project experiences, contributions, interests, and \"\n",
    "        \"communication style.\"\n",
    "    ),\n",
    "    agent=profiler,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2f810-5d27-4b63-a330-7490d01d52d4",
   "metadata": {},
   "source": [
    "You can pass a list of tasks as context to a task.\n",
    "The task then takes into account the output of those tasks in its execution.\n",
    "The task will not run until it has the output(s) from those tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b62f89-b413-44e3-9a34-eb4a4d1d4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tooo erase validationerror\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "\n",
    "class Model(BaseModel):\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "\n",
    "# simply validating a dict\n",
    "m = Model.model_validate({'a': 'e', 'b': 'r'})\n",
    "print(m)\n",
    "#> a=1 b=2\n",
    "\n",
    "# validating an existing model instance\n",
    "print(Model.model_validate(m))\n",
    "#> a=1 b=2\n",
    "\n",
    "try:\n",
    "    Model.model_validate('not an object')\n",
    "except ValidationError as exc:\n",
    "    print(repr(exc.errors()[0]['type']))\n",
    "    #> 'model_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279e8bd-77fb-47b0-85f2-4cca1f486015",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_strategy_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, tailor the resume to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"resume content. Make sure this is the best resume even but \"\n",
    "        \"don't make up any information. Update every section, \"\n",
    "        \"including the initial summary, work experience, skills, \"\n",
    "        \"and education. All to better reflect the candidate's \"\n",
    "        \"abilities and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An updated resume that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"tailored_resume.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist  # Ensure `resume_strategist` is defined\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9b814-aace-481c-8233-4dcca958a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Interview Preparer Agent: Develop Interview Materials\n",
    "interview_preparation_task = Task(\n",
    "    description=(\n",
    "        \"Create a set of potential interview questions and talking \"\n",
    "        \"points based on the tailored resume and job requirements. \"\n",
    "        \"Utilize tools to generate relevant questions and discussion \"\n",
    "        \"points. Make sure to use these question and talking points to \"\n",
    "        \"help the candiadte highlight the main points of the resume \"\n",
    "        \"and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A document containing key questions and talking points \"\n",
    "        \"that the candidate should prepare for the initial interview.\"\n",
    "    ),\n",
    "    output_file=\"interview_materials.md\",\n",
    "    context=[research_task, profile_task, resume_strategy_task],\n",
    "    agent=interview_preparer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee32595-e231-46cc-a277-aa347ec2c044",
   "metadata": {},
   "source": [
    "Running the Crew\n",
    "Set the inputs for the execution of the crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b62dff4-d761-40c4-a5c2-5ace6cf41b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_crew = Crew(\n",
    "    agents=[researcher,\n",
    "            profiler,\n",
    "            resume_strategist,\n",
    "            interview_preparer],\n",
    "\n",
    "    tasks=[research_task,\n",
    "           profile_task,\n",
    "           resume_strategy_task,\n",
    "           interview_preparation_task],\n",
    "\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661294f6-daab-400e-9961-73070c7f4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the cre\n",
    "job_application_inputs = {\n",
    "    'job_posting_url': 'https://ng.indeed.com/rc/clk?jk=19afce6bcec8451f&from=hp&tk=1ihnfq42u2e71003&bb=ZfRpFemM4XM3FnkK5r2ybfq-SIV5cB__OE2pxg5reNvsezy04szP_BGjVTeE9D4VRnpelfAaMSnjAj758rYYWKMxPcw7nvfnV5lMVOv_q9hS9ee8llvkeo-Zd2gHr_1PDaFzcSZiKG8%3D&xkcb=SoDh67M333XnXb2OAR0BbzkdCdPP',\n",
    "    'github_url': 'https://github.com/Ogechifaith-analytics/project',\n",
    "    'personal_writeup': {\n",
    "        \"personal_writeup\": (\n",
    "            \"Ogechi Faith is an accomplished Data Analyst with 3 years of experience, \"\n",
    "            \"able to work with remote and in-office teams, and proficient in multiple programming languages and frameworks. \"\n",
    "            \"She is proficient in SQL, Excel, and Power BI.\"\n",
    "        )\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dfcc16-ef82-4a73-9e17-3c60e4d5b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this execution will take a few minutes to run\n",
    "result = job_application_crew.kickoff(inputs=job_application_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348def9c-67d6-481b-9481-f3f5ec8b54fb",
   "metadata": {},
   "source": [
    "Dislplay the generated tailored_resume.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a63d61-f739-49e8-9ab1-a7c5feb72263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e86f2-a965-4c06-99bc-787d59b28c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1426b-e4fb-47d1-9c7e-43866bdab27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590e808-cac5-42f4-b0eb-6592ba027ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4e279-de4e-4416-9c45-769ddc8825ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181e9ca-99d6-43f3-93e4-7a97b86013a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecd45b-084d-4ffc-9a83-e513699ed368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939dd5d-526d-4bc1-bc9d-da3a2e303f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecad5e4-89c6-4504-bd0d-1e37c45d7d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b87f50-662a-4475-a63c-8d1d1c4ec456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c448a82-6b05-4d3e-a5e8-eef6e109b894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f21b4-3341-47fc-93d1-bbe97807e7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
